# RWKV Agent Extender

[English](ReadMe_EN.md)	[Chinese](ReadMe.md)

<font color=red size=3>提示！ 这是一个我个人用于练习的项目，如果你想一个可以实际应用的项目，可以关注比如   [闻达Wenda](https://github.com/wenda-LLM/wenda) 等项目。 </font>

## 描述

这是一个用于为RWKV提供RAG及多模态扩展功能的项目。在这里我们期望实现下面的功能：

1. 通过构建一个本地的知识库，实现基于单个或多个文档进行问答。同时也可以通过进行网络检索获取相应的知识，但这些文档内容不会被保存在知识库内。本地知识库通过向量数据库chroma，将嵌入后的文档存储起来。(已实现)

2. 另外提供了针对结构化数据进行文档问答的功能。通过让大模型与MySQL等关系型数据库进行交互，实现问答功能和对数据表的操作。(不稳定)

3. 本作品额外提供了针对图像媒体的交互功能，可以通过自然语言描述对图像进行检索，并实现基于图像上文字内容的问答功能。(不稳定)

4. 作为一个本地Agent系统，我们提供了一系列工具来作为大模型本身的扩展功能。并提供了一个简单的方式来让用户添加新的工具。(未实现)
5. 语音输入(已实现)

## 安装

<font color=red>请先确保您的LLM已经利用FastAPI等类似工具封装，或可以通过request方法进行请求，如果你使用的是RWKV，推荐使用[RWKV-Runner](https://github.com/josStorer/RWKV-Runner)</font>

将项目文件下载到本地，然后使用下面命令安装依赖。

```python
pip install -r requirements.txt
```

然后修改config.json把需要修改的部分换为自己对应的。

将rbt6模型（用于构建词嵌入）放入rbt6文件夹内，您也可以自行修改对应部分以使用其他的方法。

将Clip模型放入pretrained_models文件夹内（用于进行文本到图片的映射）。

将app.py中对应LLM的请求地址的部分换为对应自己的地址，默认地址http://127.0.0.1:8000。

运行app.py，如果运行成功，则会返回一个本地WebUI的地址。



# 设计思路

本栏主要用于备忘用



本项目以开源大模型RWKV为中心，意图设计一套在本地部署的Agent系统以解决用户个人的个性化及数据隐私问题。

本项目以Gradio为WebUI开发工具，基于Langchain构建了一条工作链：

1.输入：输入包括用户提供的对话输入和文件内容的文档输入。

​    （1）关于对话输入：

​            用户可以在WebUI界面进行键盘的文字输入和通过麦克风进行的语音输入，语音输入使用whisper模型实现。

​    （2）关于文件输入：

​            用户在WebUI界面进行文件上传后，文件会被读取。

​            如果是文本文件，则文本内容会被多种不同的模型（包括CLIP模型）进行嵌入，并分别储存在不同的数据表中，

​            如果是结构化数据，如csv,xlsx等，则会被pandas读取后存入到关系型数据库中（例如MySQL），

​            如果是音频文档，会调用whisper模型获取音频内容的文字转录，接着讲文字内容按文本的方式进行储存，

​            如果是图像文档，则会使用CLIP模型对图像内容进行嵌入并储存在向量数据库中。

2.内容处理链：

​    （1）处理模式设置

​            在WebUI界面提供了多种选项来设置大模型的不同问答模式。分为如下模式，默认只开启第一项功能：

​            1、是否开启基于本地文本知识库的问答

​            2、是否开启网络搜索

​            3、是否参考结构化数据内容

​            4、是否参考音频及图像内容

​            5、是否基于特定文档回答内容

​            6、是否启用tools

​    （2）问答处理的工作链：

​            首先检查用户的输入，读取用户的对话和文件输入：

​            检查是否开启了基于特定文档问答，如果是，则不进行对于知识库和网络内容的搜索，同时构建一个临时知识库，后续的内容将基于这个临时知识库展开。

​            如果没有开启，并且开启了基于本地的知识库问答，则启用本地知识库。

​            如果开启了网络搜索，则在搜索本地知识库的同时，还将同时开启网络搜索，搜索相关的内容，取其中最相关的n条并保存在一个临时的数据库内。

​            如果开启了参考音频和图像，则在对应的知识库内也进行搜索。

​            综合上述内容，在对应数据库内检索得到最符合问题的n个数据块，并再进行下面的操作：

​                如果启用tools，则判断用户的输入是否需要使用工具，如果判断需要则启用对应的tools，并获得执行后的结果

​                如果用户需要参考结构化数据内容，则首先根据用户的输入内容，向大模型提问并获得对应的SQL语句，执行后获得结果

​        综合以上内容，输入给大模型，并给出回答。

   （3）本地知识库检索

​            使用词嵌入的方式将文本转换为向量。同时使用多种词嵌入方式，并分别存储在不同数据库中。当需要获得内容时，同时对多个数据库检索，并使用LangChain提供的EnsembleRetriever、MergeRetriver和LongContextReorder来筛选、合并以及重排结果。

  （4）结构化数据内容处理：

​        对于结构化内容，其本身存储在关系型数据库中。当需要调用时，首先根据query构建一个SQLQueryPrompt，并输入给大模型，从而获得对应的SQL查询语句，再使用sqlalchemy执行对应语句后获得结果。

​    (5）tools：

​        当LLM想要使用工具时，首先需要对query进行一个判断，使用IsToolsUsePrompt输入给大模型，在通过query获得是否需要使用工具。如果结果为是，则根据tools.py中提供的工具列表，构建ToolGuidePrompt，输入给大模型，再输入用户的query后，使大模型生成对应的执行代码并执行。



## 使用的开源项目

[Chinese-BERT-wwm](https://github.com/ymcui/Chinese-BERT-wwm)

[EasyOCR](https://github.com/JaidedAI/EasyOCR)



